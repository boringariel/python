{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0395475b-27ad-4124-b454-ca4f6bc9df15",
   "metadata": {},
   "source": [
    "# 파이썬 셀레니움을 이용한 네이버 지도 크롤링 프로그램 만들기 (2)\n",
    "---\n",
    "이전에 파이썬 셀레니움(Python Selenium)을 이용해서 네이버 지도에 등록된 업체 정보를 크롤링해보았습니다. 그런데, 이전에 작성한 코드에는 두 가지 문제가 있어서 완전한 크롤링을 할 수 없다는 단점이 있었지요.\n",
    "</p></br></br>\n",
    "\n",
    "1. 네이버 지도는 한 페이지에 50건의 업체를 보여줍니다만, 스크롤을 내리지 않으면 일부분만 보여줍니다.\n",
    "2. 업체 세부정보를 보기 위해서는 해당 업체를 클릭해야 합니다.\n",
    "</p></br></br>\n",
    "\n",
    "그래서, 위에 언급된 두 가지 문제를 해결하는 코드를 이용해서 새로운 크롤링 프로그램을 만들어 보도록 하겠습니다. 이번에는 셀레니움을 이용한 동적 크롤링뿐만 아니라 뷰티풀수프(BeautifulSoup)를 이용한 정적 크롤링까지 병행해서 이용해 보겠습니다.\n",
    "</p></br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0207b71-6aaa-4984-b142-9efacb811f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# run webdriver\n",
    "driver = webdriver.Chrome()\n",
    "keyword = '서울 강남구 정보통신'\n",
    "url = f'https://map.naver.com/p/search/{keyword}'\n",
    "driver.get(url)\n",
    "action = ActionChains(driver)\n",
    "\n",
    "naver_res = pd.DataFrame(columns=['업체명','업종','주소','URL'])\n",
    "last_name = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4871e-15ac-45fd-86a8-2fabc05e6d18",
   "metadata": {},
   "source": [
    "</p></br></br>\n",
    "\n",
    "## 프레임 이동 구현\n",
    "---\n",
    "네이버 지도 웹페이지는 검색 결과가 노출되는 영역(searchIframe)과 업체 세부 정보가 노출되는 영역(entryIframe)이 구분되어 있습니다. 그래서, 해당 영역을 이용할 때마다 `webdriver.switch_to_.frame()` 함수를 이용해서 이용할 프레임 변경을 해 줘야 합니다. 예를 들어,\n",
    "</p></br></br>\n",
    "\n",
    "* searchIframe을 이용하기 위해서는 `driver.switch_to.frame(\"searchIframe\")`\n",
    "* entryIframe을 이용하기 위해서는 `driver.switch_to.frame(driver.find_element(By.XPATH, '//*[@id=\"entryIframe\"]'))`\n",
    "* 다른 프레임으로 이동하기 전 웹페이지 기본 프레임으로 이동하기 위해서는 `driver.switch_to.default_content()`\n",
    "</p></br></br>\n",
    "\n",
    "을 이용할 수 있습니다. 각 프레임 이름은 크롬의 개발자 도구를 이용해 조회해볼 수 있습니다.\n",
    "</p></br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769b575-14b8-482f-9775-41977f2fd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_iframe():\n",
    "    driver.switch_to.default_content()\n",
    "    driver.switch_to.frame(\"searchIframe\")\n",
    "\n",
    "def entry_iframe():\n",
    "    driver.switch_to.default_content()\n",
    "    WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"entryIframe\"]')))\n",
    "\n",
    "    for i in range(5):\n",
    "        time.sleep(.5)\n",
    "        \n",
    "        try:\n",
    "            driver.switch_to.frame(driver.find_element(By.XPATH, '//*[@id=\"entryIframe\"]'))\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def chk_names():\n",
    "    search_iframe()\n",
    "    elem = driver.find_elements(By.XPATH, '//*[@id=\"_pcmap_list_scroll_container\"]/ul/li/div[1]/div/a[1]/div/div/span[1]')\n",
    "    name_list = [e.text for e in elem]\n",
    "\n",
    "    return elem, name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb26057-1e21-441e-9984-402556d661f2",
   "metadata": {},
   "source": [
    "</p></br></br>\n",
    "\n",
    "## 크롤링 구현하기\n",
    "---\n",
    "네이버 지도 정보를 크롤링하기 위해, 파이썬으로 각 객체 이름을 클릭하고 세부정보 HTML 코드를 파싱하는 작업을 거칩니다. 각 업체별 이름은 사전 정의한 `chk_names()`를 이용해 구현하며, 반복문으로 해당 리스트를 클릭해주는 작업을 진행합니다. 세부정보가 조회된 뒤에는, 뷰티풀수프를 이용해 각 정보가 있는 코드의 클래스 이름을 지정해준 뒤, 해당 내용의 텍스트 정보를 저장하는 방식으로 동작합니다. 저장하는 정보는 `업체명, 업종, 주소, 업체 URL`입니다.\n",
    "</p></br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b16f8-0fee-4c6a-8465-cab3ac7762e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling_main():\n",
    "    global naver_res\n",
    "    addr_list = []\n",
    "    category_list = []\n",
    "    url_list = []\n",
    "    \n",
    "    for e in elem:\n",
    "        e.click()\n",
    "        entry_iframe()\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "        # append data\n",
    "        try:\n",
    "            category_list.append(soup.select('span.DJJvD')[0].text)\n",
    "        except:\n",
    "            category_list.append(float('nan'))\n",
    "        try:\n",
    "            addr_list.append(soup.select('span.LDgIH')[0].text)\n",
    "        except:\n",
    "            addr_list.append(float('nan'))\n",
    "        try:\n",
    "            url_list.append(soup.select('a.place_bluelink.CHmqa')[0]['href'])\n",
    "        except:\n",
    "            url_list.append(float('nan'))\n",
    "    \n",
    "        search_iframe()\n",
    "    \n",
    "    naver_temp = pd.DataFrame([name_list,category_list,addr_list,url_list], index=naver_res.columns).T\n",
    "    naver_res = pd.concat([naver_res, naver_temp])\n",
    "    naver_res.to_excel('./naver_crawling_result.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09b54d-a88d-42b5-b56a-7e333f00a56b",
   "metadata": {},
   "source": [
    "</p></br></br>\n",
    "\n",
    "## 페이지 이동\n",
    "---\n",
    "각 페이지를 이동하는 방법은 이전에 작성했던 파이썬 셀레니움을 이용한 네이버 지도 크롤링 프로그램 만들기 문서와 같습니다. 네이버 지도는 다음 버튼을 누르면 항상 한 페이지씩 이동하는 특징을 보이고 있는데, 이를 이용해서 계속 다음 버튼을 눌러주는 방식이죠. 만약 마지막 페이지까지 이동했다면, 이전 페이지와 같은 정보를 보이는지 확인한 뒤 종료하는 방법을 구현했습니다.\n",
    "</p></br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b03c5-e5fd-408b-9865-1a2fff7e0156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page_num = 1\n",
    "\n",
    "while 1:\n",
    "    time.sleep(.5)\n",
    "    search_iframe()\n",
    "    elem, name_list = chk_names()\n",
    "    if last_name == name_list[-1]:\n",
    "        pass\n",
    "    \n",
    "    while 1:\n",
    "        action.move_to_element(elem[-1]).perform()\n",
    "        elem, name_list = chk_names()\n",
    "        \n",
    "        if last_name == name_list[-1]:\n",
    "            break\n",
    "        else:\n",
    "            last_name = name_list[-1]\n",
    "\n",
    "    crawling_main()\n",
    "    \n",
    "    # next page\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"app-root\"]/div/div[2]/div[2]/a[7]').click()\n",
    "    time.sleep(1.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test311",
   "language": "python",
   "name": "test311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
